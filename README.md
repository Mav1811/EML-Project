# MNIST Inference Benchmark: ARM Compute Library vs MNN

This repository contains a comparative study of **MNIST CNN inference** on ARM-based systems using two different inference backends:

- **ARM Compute Library (ACL) via Arm NN**
- **MNN (Alibaba Mobile Neural Network framework)**

The project evaluates **accuracy, latency, batching behavior, and quantization effects** across different configurations.

---

## üìÅ Repository Structure


